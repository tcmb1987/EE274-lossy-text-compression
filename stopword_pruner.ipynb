{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcmb1987/EE274-lossy-text-compression/blob/main/stopword_pruner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach 1: Prune stopwords first, then embed with some word2vec <-> sentence2vec adaptation"
      ],
      "metadata": {
        "id": "HzEXiLCat3k3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msl4ci3ssHre",
        "outputId": "925a6aa2-2f0c-45e9-a8ce-836f82e9716c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "  \n",
        "def prune_sentence(sentence, stop_words):\n",
        "  word_tokens = word_tokenize(sentence)\n",
        "  return ' '.join([w for w in word_tokens if not w.lower() in stop_words and not w.lower() in string.punctuation]) "
      ],
      "metadata": {
        "id": "ggEIRfwUsLUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sent2vec.vectorizer import Vectorizer\n",
        "\n",
        "sentences = [\n",
        "    \"In the beginning, God created the heavens and the earth.\",\n",
        "    \"And the earth was without form, and void, and darkness lay upon the face of the deep.\",\n",
        "    \"And the spirit of God looked upon the face of the waters.\",\n",
        "    \"The yellow dog sits.\",\n",
        "    \"The tall woman stands.\",\n",
        "    \"The ground beef tonight was thoroughly satisfying.\",\n",
        "    \"I love to eat fried eggs.\",\n",
        "    \"My friend wants to marry me.\",\n",
        "    \"I know it is wet and the sun is not sunny, but we can have lots of good fun that is funny.\",\n",
        "    \"I know wet sun not sunny, we can lots good fun is funny\",\n",
        "    \"I know that it is wet and the sun is not sunny, however we can have lots of good fun if it is funny.\"\n",
        "]\n",
        "\n",
        "pruned_sentences = [prune_sentence(sentence, stop_words) for sentence in sentences]\n",
        "\n",
        "pruned_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arcpL5GIuJBj",
        "outputId": "b9d8eee9-9dd3-4d58-ed37-9412b72dd8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['beginning God created heavens earth',\n",
              " 'earth without form void darkness lay upon face deep',\n",
              " 'spirit God looked upon face waters',\n",
              " 'yellow dog sits',\n",
              " 'tall woman stands',\n",
              " 'ground beef tonight thoroughly satisfying',\n",
              " 'love eat fried eggs',\n",
              " 'friend wants marry',\n",
              " 'know wet sun sunny lots good fun funny',\n",
              " 'know wet sun sunny lots good fun funny',\n",
              " 'know wet sun sunny however lots good fun funny']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = Vectorizer()\n",
        "vectorizer.run(pruned_sentences)\n",
        "vectors = vectorizer.vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd3OPESouQi5",
        "outputId": "980107d8-f1d7-4d1b-d391-d0f0d79ed8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Bert distilbert-base-uncased\n",
            "Vectorization done on cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How does this thing vectorize them to all have the same dimensions? So curious.\n",
        "# Since it does, though, we can probably just use a nice supervised ML model right here to see what's up.\n",
        "\n",
        "pruned_sentence_vectors = vectors"
      ],
      "metadata": {
        "id": "DdvsYKLXRNe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_vectorizer = Vectorizer()\n",
        "original_vectorizer.run(sentences)\n",
        "original_sentence_vectors = original_vectorizer.vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBS-gBr2R0Bw",
        "outputId": "00095f1a-158a-47c2-9637-739135e45f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Bert distilbert-base-uncased\n",
            "Vectorization done on cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClEiYP9uR-vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize some sentences to determine distortion metrics (cosine distance) between original sentence with its cut version and a potential reconstructed one."
      ],
      "metadata": {
        "id": "LbO20_Fd0qNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get distance and print results."
      ],
      "metadata": {
        "id": "djRhqs9K065C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "\n",
        "dist_cut = distance.cosine(vectors[0], vectors[1])\n",
        "print(\"Distance between original sentence and cut sentence is\", dist_cut)\n",
        "dist_rec = distance.cosine(vectors[0], vectors[2])\n",
        "print(\"Distance between original sentence and reconstructed sentence is\", dist_rec)"
      ],
      "metadata": {
        "id": "6XyJQZNXujqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35146d58-784e-42c2-dc9b-b0f5760d2cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance between original sentence and cut sentence is 0.22216004133224487\n",
            "Distance between original sentence and reconstructed sentence is 0.023939311504364014\n"
          ]
        }
      ]
    }
  ]
}